<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Lei Tong</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!--<link rel="icon" type="image/png" href="images/seal_icon.png">-->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Lei Tong</name>
              </p>
              <p>
                Greetings! My name is Lei Tong (Chinese: 童磊). I am a Ph.D. student supervised by <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Prof. Huiyu Zhou</a> at the <a href="https://bipl-uol.github.io/">Biomedical Image Processing Lab (BIPL)</a>, School of Computing and Mathematical Sciences, University of Leicester and <a href="https://www.linkedin.com/in/yinhai-wang-3107a911/">Yinhai Wang</a>, <a href="https://www.linkedin.com/in/adam-corrigan-982a24b9?originalSubdomain=uk">Adam Corrigan</a> at AstraZeneca. I am funded by University of Leicester GTA studentship and AstraZeneca studentship.
              </p>
              <p>
                I received my M.Phil. in Computer Science from the University of Leicester in 2020, my B.Sc. in Computer Science from Ningbo Institute of Technology, Zhejiang University in 2017. I spent my undergraduate final year at the School of Electronics, Electrical Engineering and Computer Science in Queen's University Belfast.
              </p>
              <p style="text-align:center">
                <a href="mailto:lt228@leicester.ac.uk">Email</a> &nbsp/&nbsp
                <a>CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Fr0l4i4AAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://uk.linkedin.com/in/lei-tong-1a13a8196">Linkedin</a> &nbsp/&nbsp
                <a href="https://github.com/LeiTong02">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/leitong_pic.png" class="hoverZoomLink"></a>
              <br>
              <font>Will be replaced by a formal pic soon</font>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <ul>
               <li><font color="#FF0000">June 2023:</font> Our latest research work "A Comprehensive Framework for Cross-Batch Cell Line Identification Using Brightfield Images" is available on <a href="https://arxiv.org/abs/2306.16538">arxiv</a> and the code is accessible on <a href="https://github.com/LeiTong02/CLANet">github</a>. The dataset associated with this work is currently being prepared and will be made available in the near future.
              </li>
			   <li><font color="#FF0000">June 2022:</font> It is a great honor for me to present our work "Transforming cell line authentication with a novel image-based AI method" on the seminar "Science for the Curious" in AstraZeneca.
              </li>
			  <li><font color="#FF0000">June 2022:</font> Two-weeks internship in Astrazenca and work with UKCCB group.
              </li>
              <li><font color="#FF0000">May 2022:</font> 1 paper has been accepted by Scientific Reports. 
              </li>
			  <li><font color="#FF0000">Apr 2022:</font> Our work "Depression detection on Twitter" is described in the news: <a href="https://www.independent.co.uk/tech/twitter-bot-depressed-user-profiles-b2052664.html">Independent</a>, <a href="https://uk.finance.yahoo.com/news/bot-spot-nine-10-depressed-062932106.html">Yahoo</a>, <a href="https://metro.co.uk/2022/04/08/algorithm-can-spot-depression-in-twitter-users-with-90-accuracy-16429821/">Metro</a>, . 
              </li>
			  <li><font color="#FF0000">Mar 2022:</font> 1 paper has been accepted by IEEE trans. on Affective Computing and 1 co-authored paper has appeared on IEEE Trans. on Neural Networks and Learning Systems. 
              </li>
			  <li><font color="#FF0000">Jan 2022:</font> We have finished the extensive revision on <a href="https://arxiv.org/abs/1906.00398v3">"Cost-sensitive Boosting Pruning Trees for depression detection on Twitter"</a> and opensouced <a href="https://github.com/BIPL-UoL/Cost-Boosting-Pruning-Trees-for-depression-detection-on-Twitter">the github repo</a>.
              </li>

			  <li><font color="#FF0000">June 2021:</font> Two co-authored paper has been accepted by IEEE Trans. on Medical Image and Learning Systems and Science of The Total Environment respectively.
              </li>  
              <li><font color="#FF0000">July 2020:</font> 1 co-authored paper has appeared on IJCNN.</li>

              <li><font color="#FF0000">July 2020:</font> I am very honored to be selected to participate in The Medical Image Computing Summer School (MedICSS) at University College London (UCL)
                London, United Kingdom.
              </li>
            </ul>  
          </td>
        </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research is focusing on computer vision and machine learning, especially in biomedical image analysis, domain generalization and ensemble learning.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
			
			<tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tsne_sr.png" alt="Boundary_png" style="border-style: none" width="160" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.nature.com/articles/s41598-022-12099-3">
              <papertitle>An automated cell line authentication method for AstraZeneca global cell bank using deep neural networks on brightfield images</papertitle>
              </a>
              <br>
              <strong>Lei Tong</strong>,
              <a>Adam Corrigan</a>,
              <a>Navin Rathna Kumar</a>,
              <a>Kerry Hallbrook</a>,
              <a>Jonathan Orme</a>,
              <a>Yinhai Wang</a>,
 
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>Scientific Reports</em>, 2022
              <br>
              <a href="https://github.com/BIPL-UoL/An-Automated-Cell-Line-Authentica-tion-Method-for-AstraZeneca-Global-Cell-Bank">code</a>
              
              <p></p>
              <p>In this work, we tansform AI techniques to authentication cell lines. The results can prove our AI method has potentials to complement STR profiling.</p>
            </td>
          </tr>
		 
		 
		 
		 
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tnnls_jiang.png" alt="Boundary_png" style="border-style: none" width="160" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1906.02831.pdf">
              <papertitle>Detecting and Tracking of Multiple Mice Using Part Proposal Networks</papertitle>
              </a>
              <br>
              <a>Zheheng Jiang</a>,
              <a>Zhihua Liu</a>,
              <a>Long Chen</a>,
              <strong>Lei Tong</strong>,
              <a>Xiangrong Zhang</a>,
              <a href="https://www.comp.hkbu.edu.hk/v1/?page=profile&id=lanxiangyuan">Xiangyuan Lan</a>,
              <a href="http://www.cs.qub.ac.uk/~d.crookes/">Danny Crookes</a>,
              <a href="https://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>IEEE Trans. on Neural Networks and Learning Systems</em>, 2022
              <br>
              <a>code</a>
              /
              <a href="https://arxiv.org/pdf/1906.02831.pdf">arXiv</a>
              <p></p>
              <p>A novel method to continuously track several mice and individual parts without requiring any specific tagging.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cbpt_lei.png" alt="Boundary_png" style="border-style: none" width="160" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9691852/">
              <papertitle>Cost-sensitive Boosting Pruning Trees for depression detection on Twitter</papertitle>
              </a>
              <br>
              <Strong>Lei Tong</Strong>,
              <a>Zhihua Liu</a>,
              <a>Zheheng Jiang</a>,
              <a>Feixiang Zhou</a>,
              <a>Long Chen</a>,
              <a>Jialin Lyu</a>,
              <a>Xiangrong Zhang</a>,
              <a href="http://eecs.qmul.ac.uk/profiles/zhangqianni.html">Qianni Zhang</a>,
              <a href="https://www.brunel.ac.uk/people/abdul-h-sadka/publications">Abdul Sadka</a>,
              <a href="https://scholar.google.com/citations?user=WNY0TscAAAAJ&hl=en">Yinhai Wang</a>,
              <a href="https://www.kent.ac.uk/computing/people/3061/li-caroline">Ling Li</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>IEEE Trans. on Affective Computing</em>, 2022 
              <br>
              <a href="https://github.com/BIPL-UoL/Cost-Boosting-Pruning-Trees-for-depression-detection-on-Twitter">code</a>
              /
              <a href="https://arxiv.org/pdf/1906.00398.pdf">arXiv</a>
              <p></p>
              <p>A novel classifier, namely, Cost-sensitive Boosting Pruning Trees (CBPT), which demonstrates a strong classification ability on two publicly accessible Twitter depression detection datasets..</p>
            </td>
          </tr>
		  
		  <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/earth_xiong.jpg" alt="Boundary_png" style="border-style: none" width="160" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S0048969721003223#f0045">
              <papertitle>Towards advancing the earthquake forecasting by machine learning of satellite data</papertitle>
              </a>
              <br>
              <a>Pan Xiong</a>,
              <strong>Lei Tong</strong>,
              <a>Kun Zhang</a>,
              <a>Xuhui Shen</a>,
              <a>Roberto Battiston</a>,
              <a>Dimitar Ouzounov</a>,
              <a>Roberto Iuppa</a>,
              <a>Danny Crookes</a>,
              <a>Cheng Long</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>Science of The Total Environment</em>, 2021 
              <br>
              <a href="https://github.com/BIPL-UoL/Inverse-Boosting-Pruning-Trees">code</a>
        
              <p></p>
              <p>An AdaBoost-based ensemble framework is proposed to forecast earthquake. Our results support a Lithosphere-Atmosphere-Ionosphere Coupling during earthquakes.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/canet.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9378564">
              <papertitle>CANet: Context Aware Network for Brain Glioma Segmentation</papertitle>
              </a>
              <br>
              <a>Zhihua Liu</a>,
              <strong>Lei Tong</strong>,
              <a>Long Chen</a>,
              <a>Feixiang Zhou</a>,
              <a>Zheheng Jiang</a>,
              <a href="http://eecs.qmul.ac.uk/profiles/zhangqianni.html">Qianni Zhang</a>,
              <a href="https://scholar.google.com/citations?user=WNY0TscAAAAJ&hl=en">Yinhai Wang</a>,
              <a href="https://sites.google.com/site/caifengshan/">Caifeng Shan</a>,
              <a href="https://www.kent.ac.uk/computing/people/3061/li-caroline">Ling Li</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>IEEE Trans. on Medical Imaging</em>, 2021 
              <br>
              <a href="https://github.com/ZhihuaLiuEd/canetbrats">code</a>
              /
              <a href="https://arxiv.org/pdf/2007.07788.pdf">arXiv</a>
              <!-- /
              <a>video</a>
              /
              <a>demo</a>-->
              <p></p>
              <p>A novel approach named Context-Aware Network (CANet) for brain glioma segmentation.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/mouse.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2012.00630.pdf">
              <papertitle>Structured Context Enhancement Network for Mouse Pose Estimation</papertitle>
              </a>
              <br>
              <a>Feixiang Zhou</a>,
              <a>Zheheng Jiang</a>,
              <a>Zhihua Liu</a>,
              <a>Fang Chen</a>,
              <a>Long Chen</a>,
              <strong>Lei Tong</strong>,
              <a>Zhile Yang</a>,
              <a>Haikuan Wang</a>,
              <a>Minrui Fei</a>,
              <a href="https://www.kent.ac.uk/computing/people/3061/li-caroline">Ling Li</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>IEEE Trans. on Circuits and Systems for Video Technology</em>, 2021 
              <br>
              <a>code</a>
              /
              <a href="https://arxiv.org/pdf/2012.00630.pdf">arXiv</a>
              <!-- /
              <a>video</a>
              /
              <a>demo</a>-->
              <p></p>
              <p>A novel Hourglass network based model, namely Graphical Model based Structured Context Enhancement Network (GMSCENet), quantifies mouse pose estimation from videos.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/longchenTCSVT.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9245532">
              <papertitle>Perceptual underwater image enhancement with deep learning and physical priors</papertitle>
              </a>
              <br>
              <a>Long Chen</a>,
              <a>Zheheng Jiang</a>,
              <strong>Lei Tong</strong>,
              <a>Zhihua Liu</a>,
              <a>Aite Zhao</a>,
              <a href="http://eecs.qmul.ac.uk/profiles/zhangqianni.html">Qianni Zhang</a>,
              <a>Junyu Dong</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>IEEE Trans. on Circuits and Systems for Video Technology</em>, 2020 
              <br>
              <a href="https://github.com/LongChenCV/HybridDetectionGAN">code</a>
              /
              <a href="https://arxiv.org/abs/2008.09697">arXiv</a>
              <p></p>
              <p>In this paper, we propose two perceptual enhancement models, each of which uses a deep enhancement model with a detection perceptor. The detection perceptor provides coherent information in the form of gradients to the enhancement model, guiding the enhancement model to generate patch level visually pleasing images or detection favourable images.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/braintumorsurvey.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2007.09479.pdf">
              <papertitle>Deep Learning Based Brain Tumor Segmentation: A Survey</papertitle>
              </a>
              <br>
              <a>Zhihua Liu</a>,
              <strong>Lei Tong</strong>,
              <a>Zheheng Jiang</a>,
              <a>Long Chen</a>,
              <a>Feixiang Zhou</a>,
              <a href="http://eecs.qmul.ac.uk/profiles/zhangqianni.html">Qianni Zhang</a>,
              <a href="https://scholar.google.co.uk/citations?user=G6AdRfwAAAAJ&hl=en">Xiangrong Zhang</a>,
              <a href="https://scholar.google.co.uk/citations?user=B5WAkz4AAAAJ&hl=en">Yaochu Jin</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>arXiv</em>, 2020 
              <br>
              <a href="https://github.com/ZhihuaLiuEd/SoTA-Brain-Tumor-Segmentation">code</a>
              /
              <a href="https://arxiv.org/pdf/2007.09479.pdf">arXiv</a>
              <!-- /
              <a>video</a>
              /
              <a>demo</a>-->
              <p></p>
              <p> Considering stateof-the-art technologies and their performance, the purpose of this paper is to provide a comprehensive survey of recently developed deep learning based brain tumor segmentation techniques.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/swipenet.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9207506">
              <papertitle>Underwater object detection using Invert Multi-Class Adaboost with deep learning</papertitle>
              </a>
              <br>
              <a>Long Chen</a>,
              <a>Zhihua Liu</a>,
              <strong>Lei Tong</strong>,
              <a>Zheheng Jiang</a>,
              <a>Shengke Wang</a>,
              <a>Junyu Dong</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>International Joint Conference on Neural Networks (IJCNN)</em>, 2020 
              <br>
              <a href="https://github.com/LongChenCV/SWIPENet">code</a>
              /
              <a href="https://arxiv.org/pdf/2005.11552.pdf">arXiv</a>
              <p></p>
              <p>Sample-WeIghted hyPEr Network (SWIPENet) for underwater small object detection.</p>
            </td>
          </tr>

        </tbody></table>
		<!--
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Projects</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/dominos.png"></td>
            <td width="75%" valign="center">
              <a href="https://cordis.europa.eu/project/rcn/211947/en">Smart distribution grid: a market driven approach for the next generation of advanced operation models and services (DOMINOES)</a>
              <br>
              <br>
              <font>December 2020-June 2021</font>
            </td>
          </tr>
          
          <tr onmouseout="flyspin_stop()" onmouseover="flyspin_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='flyspin' class='hidden'><img src="images/Mosaicing2.gif"></div>
              <div id='flystill'>
                <a href="images/Mosaicing.gif"><img src="images/Mosaicingbegin.png"></a>
              </div>
              <script type="text/javascript">
                function flyspin_start() {
                  document.getElementById('flyspin').style.display = 'inline';
                  document.getElementById('flystill').style.display = 'none';
                }

                function flyspin_stop() {
                  document.getElementById('flyspin').style.display = 'none';
                  document.getElementById('flystill').style.display = 'inline';
                }
                flyspin_stop()
              </script>
            </td>
            <td width="75%" valign="center">
              <a>3D Reconstruction and Video Mosaicking with Applications to Fetoscopy</a>
              <br>
              <br>
              <font>July 2020</font>
              <br>
              <br>
              <font>Group project during UCL Medical Image Computing Summer School (MedICSS) 2020.</font>
              <br>
              <br>
              <a href="https://drive.google.com/file/d/1oJa2dJFrfyHq2mTDQ2JJryU2ItkJlMap/view?usp=sharing">Presentation Slide</a>
              /
              <a href="https://arxiv.org/pdf/1907.06543.pdf">Related Paper</a>
              /
              <a href="https://www.ucl.ac.uk/interventional-surgical-sciences/fetoscopy-placenta-data">Related Dataset</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/astrosat.png"></td>
            <td width="75%" valign="center">
              <a href="https://www.sprint.ac.uk/people/huiyu-joe-zhou/">Automated analysis of housing construction progress through remote sensing</a>
              <br>
              <br>
              <font>April 2020-April 2021</font>
              <br>
              <br>
              <font>Collabrative work with <a href="https://astrosat.net/">Stevenson Astrosat Ltd</a>.</font>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/pointcloudjd.png"></td>
            <td width="75%" valign="center">
              <a>Object detection in 3D point cloud</a>
              <br>
              <br>
              <font>Jan 2017-Sep 2018</font>
              <br>
              <br>
              <font>Industrial research and engineering work at</font> <a href="https://www.jdl.cn/">JD Logistics, JD.com.</a><font>Focused on vehicle, bicycle and pedestrian detection from 3D point cloud generated from LiDAR. Also focused on engineering work within point cloud data storge, data retrival, data access authentication development.</font>
            </td>
          </tr>
        </tbody></table>
		-->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching Assistant</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/uolcs.jpg"></td>
            <td width="75%" valign="center">
              <font color="#FF0000">2020-2023</font>
              <br>
			  <font>CO7214 Service-Oriented Architecture</font>
			  <br>
			  <font>CO7095 Software Measurement and Quality Assurance</font>
			  <br>
			  <font>CO4105 Advanced C++ Programming</font>
			  <br>
              <font>CO3002 Analysis and Design of Algorithms</font>
              <br>
			  <font>CO2102 Database and Domain Modelling</font>
			  <br>
              <font>CO1105 Introduction to Object Oriented Programming</font>
              <br>
            </td>
          </tr>
        </tbody></table>
		<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=xoJEqntTcbsIbuduO8-Knb9Sv5k97dEA1va-s4Uw7ug"></script>
		<!--
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Others</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td width="75%" valign="center">
			
              <font>I like traveling and photography. Here is my <a href="https://www.flickr.com/photos/192894210@N08/">flickr</a>.</font>
              <br>
              <br>
			  
              <font>I also like sports, especially table tennis. I started to receive professional table tennis training from the age of 5, got into the school team, and gave up training in high school because of the college entrance examination. Overall it's great to play one or two games with friends to relieve stress.</font>
            </td>
          </tr>
        </tbody></table>
		-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <font><a href="https://github.com/jonbarron/website">Website template</a> is from <a href="https://jonbarron.info/">Jon Barron</a>.<font> 
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
