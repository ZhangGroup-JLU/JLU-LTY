<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Tengyue LI</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!--<link rel="icon" type="image/png" href="images/seal_icon.png">-->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Tengyue LI</name>
              </p>  
              <p>
                Greetings! My name is Tengyue LI (Chinese: 李腾跃, Email: litengyue@jlu.edu.cn). I am currently a postdoctoral researcher under the guidance of <a href="https://const.jlu.edu.cn/info/1113/2914.htm">Prof. Wen Zhang</a> at the <a href="https://zhanggroup-jlu.github.io/">Rock Mass Structure and Geological Hazards Lab (RMSGHL)</a>, which is part of the College of Construction Engineering at the Jilin University of China.
              </p>
              <p>
                I received my Bachelor, Master, and PhD degrees from Ocean University of China in 2013, 2015, and 2022, respectively. I was funded by the China Scholarship Council (CSC) to carry out my research in image analysis at University of Leicester of United Kindom during the PhD period. I ever worked at Hisense as a hardware engineering designer.
              </p>
             
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/TengyueLi2.jpg" class="hoverZoomLink"></a>
              <br>
              
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Education & Work</heading>
            <ul>
	       <li><font color="#FF0000">2022.08-Current:</font> Jilin University of China -- Engineering Geology -- Postdoctoral Researcher
              </li>
               <li><font color="#FF0000">2017.09-2022.06:</font> Ocean University of China -- Intelligence Information and Communication System -- PhD Degree
              </li>
			   <li><font color="#FF0000">2021.01-2022.03:</font> University of Leicester of United Kingdom -- Computer Science -- Visiting Scholar
              </li>
			  <li><font color="#FF0000">2015.08-2017.08:</font> Hisense Research and Development Center -- Hardware Engineering Designer
              </li>
              <li><font color="#FF0000">2013.09-2015.06:</font> Ocean University of China -- Optical Engineering -- Master Degree 
              </li>
			  <li><font color="#FF0000">2009.09-2013.06:</font> Ocean University of China -- Electronic Information Science and Tecnology -- Bachelor Degree
            </ul>  
          </td>
        </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research is focusing on computer vision, machine learning, and robotics, especially in image analysis for the high steep slopes and underwater scenes (including 3D reconstruction, image processing, object recognition etc.).
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
			
			<tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tsne_sr.png" alt="Boundary_png" style="border-style: none" width="160" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.nature.com/articles/s41598-022-12099-3">
              <papertitle>An automated cell line authentication method for AstraZeneca global cell bank using deep neural networks on brightfield images</papertitle>
              </a>
              <br>
              <strong>Lei Tong</strong>,
              <a>Adam Corrigan</a>,
              <a>Navin Rathna Kumar</a>,
              <a>Kerry Hallbrook</a>,
              <a>Jonathan Orme</a>,
              <a>Yinhai Wang</a>,
 
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>Scientific Reports</em>, 2022
              <br>
              <a href="https://github.com/BIPL-UoL/An-Automated-Cell-Line-Authentica-tion-Method-for-AstraZeneca-Global-Cell-Bank">code</a>
              
              <p></p>
              <p>In this work, we tansform AI techniques to authentication cell lines. The results can prove our AI method has potentials to complement STR profiling.</p>
            </td>
          </tr>
		 
		 
		 
		 
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tnnls_jiang.png" alt="Boundary_png" style="border-style: none" width="160" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1906.02831.pdf">
              <papertitle>Detecting and Tracking of Multiple Mice Using Part Proposal Networks</papertitle>
              </a>
              <br>
              <a>Zheheng Jiang</a>,
              <a>Zhihua Liu</a>,
              <a>Long Chen</a>,
              <strong>Lei Tong</strong>,
              <a>Xiangrong Zhang</a>,
              <a href="https://www.comp.hkbu.edu.hk/v1/?page=profile&id=lanxiangyuan">Xiangyuan Lan</a>,
              <a href="http://www.cs.qub.ac.uk/~d.crookes/">Danny Crookes</a>,
              <a href="https://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>IEEE Trans. on Neural Networks and Learning Systems</em>, 2022
              <br>
              <a>code</a>
              /
              <a href="https://arxiv.org/pdf/1906.02831.pdf">arXiv</a>
              <p></p>
              <p>A novel method to continuously track several mice and individual parts without requiring any specific tagging.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cbpt_lei.png" alt="Boundary_png" style="border-style: none" width="160" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9691852/">
              <papertitle>Cost-sensitive Boosting Pruning Trees for depression detection on Twitter</papertitle>
              </a>
              <br>
              <Strong>Lei Tong</Strong>,
              <a>Zhihua Liu</a>,
              <a>Zheheng Jiang</a>,
              <a>Feixiang Zhou</a>,
              <a>Long Chen</a>,
              <a>Jialin Lyu</a>,
              <a>Xiangrong Zhang</a>,
              <a href="http://eecs.qmul.ac.uk/profiles/zhangqianni.html">Qianni Zhang</a>,
              <a href="https://www.brunel.ac.uk/people/abdul-h-sadka/publications">Abdul Sadka</a>,
              <a href="https://scholar.google.com/citations?user=WNY0TscAAAAJ&hl=en">Yinhai Wang</a>,
              <a href="https://www.kent.ac.uk/computing/people/3061/li-caroline">Ling Li</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>IEEE Trans. on Affective Computing</em>, 2022 
              <br>
              <a href="https://github.com/BIPL-UoL/Cost-Boosting-Pruning-Trees-for-depression-detection-on-Twitter">code</a>
              /
              <a href="https://arxiv.org/pdf/1906.00398.pdf">arXiv</a>
              <p></p>
              <p>A novel classifier, namely, Cost-sensitive Boosting Pruning Trees (CBPT), which demonstrates a strong classification ability on two publicly accessible Twitter depression detection datasets..</p>
            </td>
          </tr>
		  
		  <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/earth_xiong.jpg" alt="Boundary_png" style="border-style: none" width="160" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S0048969721003223#f0045">
              <papertitle>Towards advancing the earthquake forecasting by machine learning of satellite data</papertitle>
              </a>
              <br>
              <a>Pan Xiong</a>,
              <strong>Lei Tong</strong>,
              <a>Kun Zhang</a>,
              <a>Xuhui Shen</a>,
              <a>Roberto Battiston</a>,
              <a>Dimitar Ouzounov</a>,
              <a>Roberto Iuppa</a>,
              <a>Danny Crookes</a>,
              <a>Cheng Long</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>Science of The Total Environment</em>, 2021 
              <br>
              <a href="https://github.com/BIPL-UoL/Inverse-Boosting-Pruning-Trees">code</a>
        
              <p></p>
              <p>An AdaBoost-based ensemble framework is proposed to forecast earthquake. Our results support a Lithosphere-Atmosphere-Ionosphere Coupling during earthquakes.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/canet.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9378564">
              <papertitle>CANet: Context Aware Network for Brain Glioma Segmentation</papertitle>
              </a>
              <br>
              <a>Zhihua Liu</a>,
              <strong>Lei Tong</strong>,
              <a>Long Chen</a>,
              <a>Feixiang Zhou</a>,
              <a>Zheheng Jiang</a>,
              <a href="http://eecs.qmul.ac.uk/profiles/zhangqianni.html">Qianni Zhang</a>,
              <a href="https://scholar.google.com/citations?user=WNY0TscAAAAJ&hl=en">Yinhai Wang</a>,
              <a href="https://sites.google.com/site/caifengshan/">Caifeng Shan</a>,
              <a href="https://www.kent.ac.uk/computing/people/3061/li-caroline">Ling Li</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>IEEE Trans. on Medical Imaging</em>, 2021 
              <br>
              <a href="https://github.com/ZhihuaLiuEd/canetbrats">code</a>
              /
              <a href="https://arxiv.org/pdf/2007.07788.pdf">arXiv</a>
              <!-- /
              <a>video</a>
              /
              <a>demo</a>-->
              <p></p>
              <p>A novel approach named Context-Aware Network (CANet) for brain glioma segmentation.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/mouse.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2012.00630.pdf">
              <papertitle>Structured Context Enhancement Network for Mouse Pose Estimation</papertitle>
              </a>
              <br>
              <a>Feixiang Zhou</a>,
              <a>Zheheng Jiang</a>,
              <a>Zhihua Liu</a>,
              <a>Fang Chen</a>,
              <a>Long Chen</a>,
              <strong>Lei Tong</strong>,
              <a>Zhile Yang</a>,
              <a>Haikuan Wang</a>,
              <a>Minrui Fei</a>,
              <a href="https://www.kent.ac.uk/computing/people/3061/li-caroline">Ling Li</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>IEEE Trans. on Circuits and Systems for Video Technology</em>, 2021 
              <br>
              <a>code</a>
              /
              <a href="https://arxiv.org/pdf/2012.00630.pdf">arXiv</a>
              <!-- /
              <a>video</a>
              /
              <a>demo</a>-->
              <p></p>
              <p>A novel Hourglass network based model, namely Graphical Model based Structured Context Enhancement Network (GMSCENet), quantifies mouse pose estimation from videos.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/longchenTCSVT.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9245532">
              <papertitle>Perceptual underwater image enhancement with deep learning and physical priors</papertitle>
              </a>
              <br>
              <a>Long Chen</a>,
              <a>Zheheng Jiang</a>,
              <strong>Lei Tong</strong>,
              <a>Zhihua Liu</a>,
              <a>Aite Zhao</a>,
              <a href="http://eecs.qmul.ac.uk/profiles/zhangqianni.html">Qianni Zhang</a>,
              <a>Junyu Dong</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>IEEE Trans. on Circuits and Systems for Video Technology</em>, 2020 
              <br>
              <a href="https://github.com/LongChenCV/HybridDetectionGAN">code</a>
              /
              <a href="https://arxiv.org/abs/2008.09697">arXiv</a>
              <p></p>
              <p>In this paper, we propose two perceptual enhancement models, each of which uses a deep enhancement model with a detection perceptor. The detection perceptor provides coherent information in the form of gradients to the enhancement model, guiding the enhancement model to generate patch level visually pleasing images or detection favourable images.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/braintumorsurvey.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2007.09479.pdf">
              <papertitle>Deep Learning Based Brain Tumor Segmentation: A Survey</papertitle>
              </a>
              <br>
              <a>Zhihua Liu</a>,
              <strong>Lei Tong</strong>,
              <a>Zheheng Jiang</a>,
              <a>Long Chen</a>,
              <a>Feixiang Zhou</a>,
              <a href="http://eecs.qmul.ac.uk/profiles/zhangqianni.html">Qianni Zhang</a>,
              <a href="https://scholar.google.co.uk/citations?user=G6AdRfwAAAAJ&hl=en">Xiangrong Zhang</a>,
              <a href="https://scholar.google.co.uk/citations?user=B5WAkz4AAAAJ&hl=en">Yaochu Jin</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>arXiv</em>, 2020 
              <br>
              <a href="https://github.com/ZhihuaLiuEd/SoTA-Brain-Tumor-Segmentation">code</a>
              /
              <a href="https://arxiv.org/pdf/2007.09479.pdf">arXiv</a>
              <!-- /
              <a>video</a>
              /
              <a>demo</a>-->
              <p></p>
              <p> Considering stateof-the-art technologies and their performance, the purpose of this paper is to provide a comprehensive survey of recently developed deep learning based brain tumor segmentation techniques.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/swipenet.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9207506">
              <papertitle>Underwater object detection using Invert Multi-Class Adaboost with deep learning</papertitle>
              </a>
              <br>
              <a>Long Chen</a>,
              <a>Zhihua Liu</a>,
              <strong>Lei Tong</strong>,
              <a>Zheheng Jiang</a>,
              <a>Shengke Wang</a>,
              <a>Junyu Dong</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>International Joint Conference on Neural Networks (IJCNN)</em>, 2020 
              <br>
              <a href="https://github.com/LongChenCV/SWIPENet">code</a>
              /
              <a href="https://arxiv.org/pdf/2005.11552.pdf">arXiv</a>
              <p></p>
              <p>Sample-WeIghted hyPEr Network (SWIPENet) for underwater small object detection.</p>
            </td>
          </tr>

        </tbody></table>
		<!--
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Projects</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/dominos.png"></td>
            <td width="75%" valign="center">
              <a href="https://cordis.europa.eu/project/rcn/211947/en">Smart distribution grid: a market driven approach for the next generation of advanced operation models and services (DOMINOES)</a>
              <br>
              <br>
              <font>December 2020-June 2021</font>
            </td>
          </tr>
          
          <tr onmouseout="flyspin_stop()" onmouseover="flyspin_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='flyspin' class='hidden'><img src="images/Mosaicing2.gif"></div>
              <div id='flystill'>
                <a href="images/Mosaicing.gif"><img src="images/Mosaicingbegin.png"></a>
              </div>
              <script type="text/javascript">
                function flyspin_start() {
                  document.getElementById('flyspin').style.display = 'inline';
                  document.getElementById('flystill').style.display = 'none';
                }

                function flyspin_stop() {
                  document.getElementById('flyspin').style.display = 'none';
                  document.getElementById('flystill').style.display = 'inline';
                }
                flyspin_stop()
              </script>
            </td>
            <td width="75%" valign="center">
              <a>3D Reconstruction and Video Mosaicking with Applications to Fetoscopy</a>
              <br>
              <br>
              <font>July 2020</font>
              <br>
              <br>
              <font>Group project during UCL Medical Image Computing Summer School (MedICSS) 2020.</font>
              <br>
              <br>
              <a href="https://drive.google.com/file/d/1oJa2dJFrfyHq2mTDQ2JJryU2ItkJlMap/view?usp=sharing">Presentation Slide</a>
              /
              <a href="https://arxiv.org/pdf/1907.06543.pdf">Related Paper</a>
              /
              <a href="https://www.ucl.ac.uk/interventional-surgical-sciences/fetoscopy-placenta-data">Related Dataset</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/astrosat.png"></td>
            <td width="75%" valign="center">
              <a href="https://www.sprint.ac.uk/people/huiyu-joe-zhou/">Automated analysis of housing construction progress through remote sensing</a>
              <br>
              <br>
              <font>April 2020-April 2021</font>
              <br>
              <br>
              <font>Collabrative work with <a href="https://astrosat.net/">Stevenson Astrosat Ltd</a>.</font>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/pointcloudjd.png"></td>
            <td width="75%" valign="center">
              <a>Object detection in 3D point cloud</a>
              <br>
              <br>
              <font>Jan 2017-Sep 2018</font>
              <br>
              <br>
              <font>Industrial research and engineering work at</font> <a href="https://www.jdl.cn/">JD Logistics, JD.com.</a><font>Focused on vehicle, bicycle and pedestrian detection from 3D point cloud generated from LiDAR. Also focused on engineering work within point cloud data storge, data retrival, data access authentication development.</font>
            </td>
          </tr>
        </tbody></table>
		-->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Projects</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/jlu2.png"></td>
            <td width="75%" valign="center">
			  <font>2023.06 The China Postdoctoral Science Fund</font>
			  <br>
			  <font>2023.05 The Open Fund of Badong National Observation and Research Station of Geohazards</font>
			  <br>
			  <font>2018.09 Independent Project for Graduate Students of Ocean University of China</font>
			  <br>
            </td>
          </tr>
        </tbody></table>
        <p><center>
      	<div id="clustrmaps-widget" style="width:10%">
      		<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=xoJEqntTcbsIbuduO8-Knb9Sv5k97dEA1va-s4Uw7ug"></script>
      		<noscript><a href="https://clustrmaps.com/site/1bvhq"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=xoJEqntTcbsIbuduO8-Knb9Sv5k97dEA1va-s4Uw7ug&cl=ffffff" /></a></noscript>

	</div>        
	<br>
     
      </center></p>
        
        
		
		<!--
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Others</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td width="75%" valign="center">
			
              <font>I like traveling and photography. Here is my <a href="https://www.flickr.com/photos/192894210@N08/">flickr</a>.</font>
              <br>
              <br>
			  
              <font>I also like sports, especially table tennis. I started to receive professional table tennis training from the age of 5, got into the school team, and gave up training in high school because of the college entrance examination. Overall it's great to play one or two games with friends to relieve stress.</font>
            </td>
          </tr>
        </tbody></table>
		-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <font>&copy; Tengyue Li | Last updated: Sep 2023<font> 
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
  
</body>

</html>
